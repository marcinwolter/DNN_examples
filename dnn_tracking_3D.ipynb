{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "dnn_tracking_3D.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcinwolter/DNN_examples/blob/master/dnn_tracking_3D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAzAz_c-HhOA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Reconstructs straight tracks in 3D (with noise and inefficiency)\n",
        "Using google TPUs to speed up the training\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "\n",
        "!pip install keras_sequential_ascii\n",
        "\n",
        "#import ROOT\n",
        "#from ROOT import TMVA, TFile, TTree, TCut, TChain, TString, TF1, TGraphErrors, TFile, TNtuple, TCanvas\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Package imports\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import os\n",
        "import pprint\n",
        "\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D, RepeatVector, LSTM, TimeDistributed\n",
        "from keras.layers import Conv3D, MaxPooling3D\n",
        "from keras.layers import Reshape\n",
        "from keras.models import Sequential\n",
        "from keras_sequential_ascii import sequential_model_to_ascii_printout\n",
        "from keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import SGD, RMSprop, Adam, Nadam\n",
        "\n",
        "import sys\n",
        "import time\n",
        "\n",
        "np.random.seed(2348)\n",
        "\n",
        "batch_size = 5000\n",
        "batch_size_NN = 2*128 #128\n",
        "epochs = 512 #512\n",
        "pre_epochs =  16 #32 epochs for pre-traing using rms optimizer\n",
        "post_epochs = 16 #64 post-training using SGD\n",
        "steps_per_epoch = 2*8 #4*8\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28  #28, 28\n",
        "\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "# Data parameters\n",
        "det_width = img_rows  # stupid, to be changed\n",
        "det_depth = img_cols\n",
        "det_shape = (det_width, det_width, det_depth)\n",
        "\n",
        "\n",
        "# Number of tracks in each event follows Poisson distribution\n",
        "mean_tracks = 2\n",
        "max_tracks  = 2\n",
        "\n",
        "#probability of noise and the efficiency<1\n",
        "prob_noise = 0.000\n",
        "efficiency = 0.90\n",
        "\n",
        "#slope multiplicator - reduce the slope to slope_mult*max_slope\n",
        "slope_mult = 0.4\n",
        "\n",
        "\n",
        "y_new = []\n",
        "\n",
        "# ### Functions for toy data generation\n",
        "\n",
        "\n",
        "def simulate_straight_track(b2x, bx, b2y, by, det_shape):\n",
        "    \"\"\"\n",
        "    Simulate detector data for one straight track.\n",
        "    Parameters:\n",
        "        b2x, b2y: track last layer intercept\n",
        "        bx, by: track first-layer intercept parameter (detector entry point)\n",
        "        det_shape: tuple of detector shape: (width, width, depth)\n",
        "    Returns:\n",
        "        ndarray of binary detector data for one track.\n",
        "    \"\"\"\n",
        "    x = np.zeros(det_shape)\n",
        "    idz = np.arange(det_shape[2])\n",
        "    hitsx = (idz*(b2x-bx)/det_depth + bx +0.5).astype(int)  ## +0.5 to get rounding, not clipping\n",
        "    hitsy = (idz*(b2y-by)/det_depth + by +0.5).astype(int)  ## +0.5 to get rounding, not clipping\n",
        "    # implement hit efficiency\n",
        "    for i in range(det_shape[0]):\n",
        "        if (np.random.random() > efficiency):\n",
        "            hitsx[i]=0\n",
        "            hitsy[i]=0\n",
        "    #print (\"HITS = \",hits)\n",
        "    valid = (hitsx > 0) & (hitsx < det_shape[0]) & (hitsy > 0) & (hitsy < det_shape[1])\n",
        "    x[hitsx[valid], hitsy[valid], idz[valid]] = 1\n",
        "    return x\n",
        "\n",
        "# Generator for single-track events\n",
        "def gen_tracks(batch_size=batch_size, det_shape=det_shape):\n",
        "    \"\"\"Arguments:\n",
        "         batch_size: number of events to yield for each call\n",
        "       Yields: batches of training data for use with the keras fit_generator function\n",
        "    \"\"\"\n",
        "    while True:\n",
        "        # Entry and exit points are randomized\n",
        "        bsx = np.random.random_sample(size=batch_size)*(det_width-6)+3\n",
        "        b2sx = np.random.random_sample(size=batch_size)*(det_width-6)+3\n",
        "        # restrict the slope of a track to slope_mult*slope\n",
        "        b2sx = bsx + slope_mult*(b2sx-bsx)\n",
        "        \n",
        "        bsy = np.random.random_sample(size=batch_size)*(det_width-6)+3\n",
        "        b2sy = np.random.random_sample(size=batch_size)*(det_width-6)+3\n",
        "        # restrict the slope of a track to slope_mult*slope\n",
        "        b2sy = bsy + slope_mult*(b2sy-bsy)\n",
        "        \n",
        "        tracks = np.zeros((batch_size, 1, det_depth, det_width, det_width))\n",
        "        params = zip(bsx, b2sx, bsy, b2sy )\n",
        "        for i, (pbx, pb2x, pby, pb2y) in enumerate(params):\n",
        "            tracks[i,0] = simulate_straight_track(pb2x, pbx, pb2y, pby, det_shape)\n",
        "###        targets = zip(bsx, msx, bsy, msy)\n",
        "        targets = zip(bsx/det_width, (b2sx-bsx)/det_depth/slope_mult, \n",
        "                      bsy/det_width, (b2sy-bsy)/det_depth/slope_mult )  # save b and b2 as targets\n",
        "        targets = np.asarray(targets)\n",
        "        yield tracks, targets\n",
        "\n",
        "# Generator for multi-track events.\n",
        "# Each event contains exactly n_tracks tracks.\n",
        "# The target track parameters are sorted in increasing order of X intercept.\n",
        "def gen_n_tracks(batch_size=batch_size, det_shape=det_shape, n_tracks=mean_tracks):\n",
        "    gen_single = gen_tracks(batch_size=n_tracks, det_shape=det_shape)\n",
        "    while True:\n",
        "        batch_events = np.zeros((batch_size, 1, det_depth, det_width, det_width))\n",
        "#        batch_targets = -np.ones((batch_size, n_tracks, 4))\n",
        "        batch_targets = -np.ones((batch_size, max_tracks, 4))\n",
        "        #print(\"batch_targets 0 \",batch_targets.shape)\n",
        "        for n in range(batch_size):\n",
        "            tracks,targets = gen_single.next()\n",
        "            batch_events[n,0] = np.clip( sum( tracks ), 0, 1)\n",
        "            event_targets = np.asarray(targets)\n",
        "\n",
        "            #print(\"event_targets\",event_targets,targets)\n",
        "            batch_targets[n] = event_targets[event_targets[:,0].argsort()] # sort by first column\n",
        "            #add empty rows to get the size of max_tracks\n",
        "            #for k in range(max_tracks-n_tracks):\n",
        "            ###batch_targets[n] = event_targets  #do not sort\n",
        "            #print(\"batch_events \",batch_events.shape)\n",
        "            #print(\"batch_targets \",batch_targets.shape)\n",
        "        yield batch_events, batch_targets\n",
        "\n",
        "# Generator for multi-track events.\n",
        "# Each event contains up to max_tracks tracks.\n",
        "# The target track parameters are sorted in increasing order of intercept.\n",
        "def gen_multi_tracks(batch_size=batch_size, det_shape=det_shape, mean_tracks=mean_tracks):\n",
        "    gen_single = gen_tracks(batch_size=max_tracks, det_shape=det_shape)\n",
        "    while True:\n",
        "        batch_events = np.zeros((batch_size, 1, det_depth, det_width, det_width))\n",
        "        batch_targets = -np.ones((batch_size, max_tracks, 4))\n",
        "        for n in range(batch_size):\n",
        "            num_tracks = min( max_tracks, np.random.poisson(mean_tracks) )\n",
        "            tracks,targets = gen_single.next()\n",
        "            batch_events[n,0] = np.clip( sum( tracks[:num_tracks] ), 0, 1)\n",
        "            event_targets = np.asarray(targets[:num_tracks])\n",
        "            batch_targets[n,:num_tracks] = event_targets[event_targets[:,0].argsort()] # sort by first column            \n",
        "        yield batch_events, batch_targets\n",
        "\n",
        "\n",
        "def gen_noise(batch_size=batch_size, det_shape=det_shape, prob_noise=prob_noise):\n",
        "\n",
        "        batch_events = np.zeros((batch_size, 1, det_depth, det_width, det_width))\n",
        "        for n in range(batch_size):\n",
        "\n",
        "            for i in range(det_depth):\n",
        "               for j in range(det_width):\n",
        "                  for k in range(det_width):\n",
        "                     if np.random.random()<prob_noise:\n",
        "                        batch_events[n,0,i,j,k]=1\n",
        "\n",
        "\n",
        "        yield batch_events\n",
        "\n",
        "\n",
        "####################################################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "##########################################################################################\n",
        "\n",
        "def get_activations(model, model_inputs, print_shape_only=False, layer_name=None):\n",
        "    print('----- activations -----')\n",
        "    activations = []\n",
        "    inp = model.input\n",
        "\n",
        "    model_multi_inputs_cond = True\n",
        "    if not isinstance(inp, list):\n",
        "        # only one input! let's wrap it in a list.\n",
        "        inp = [inp]\n",
        "        model_multi_inputs_cond = False\n",
        "\n",
        "    outputs = [layer.output for layer in model.layers if\n",
        "               layer.name == layer_name or layer_name is None]  # all layer outputs\n",
        "\n",
        "\n",
        "\n",
        "    funcs = [K.function(inp + [K.learning_phase()], [out]) for out in outputs]  # evaluation functions\n",
        "\n",
        "    if model_multi_inputs_cond:\n",
        "        list_inputs = []\n",
        "        list_inputs.extend(model_inputs)\n",
        "        list_inputs.append(0.)\n",
        "    else:\n",
        "        list_inputs = [model_inputs, 0.]\n",
        "\n",
        "    # Learning phase. 0 = Test mode (no dropout or batch normalization)\n",
        "    # layer_outputs = [func([model_inputs, 0.])[0] for func in funcs]\n",
        "    layer_outputs = [func(list_inputs)[0] for func in funcs]\n",
        "    for layer_activations in layer_outputs:\n",
        "        activations.append(layer_activations)\n",
        "        if print_shape_only:\n",
        "            print(layer_activations.shape)\n",
        "        else:\n",
        "            print(layer_activations)\n",
        "    return activations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#####################################################################################\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z02_bQlZsAu-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# the data, split between train and test sets\n",
        "#(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "###x_train, y_train = gen_n_tracks(batch_size=batch_size).next()\n",
        "x_test, y_test = gen_n_tracks(batch_size=batch_size, n_tracks=mean_tracks).next()\n",
        "\n",
        "###y_train = y_train\n",
        "###y_test = y_test\n",
        "\n",
        "# add noise\n",
        "###noise_train = gen_noise(batch_size=batch_size).next()\n",
        "noise_test = gen_noise(batch_size=batch_size, prob_noise=prob_noise).next()\n",
        "###x_train = x_train+noise_train\n",
        "x_test  = x_test+noise_test\n",
        "\n",
        "\n",
        "###print(\"x_train \",x_train.shape)\n",
        "###print(\"y_train \",y_train.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#print(x_train[0,0])\n",
        "#print(\"Train targets \",y_train[0])\n",
        "#print(x_test[0,0])\n",
        "#print(\"Test targets \",y_test[0])\n",
        "\n",
        "\n",
        "#\n",
        "# if K.image_data_format() == 'channels_first':\n",
        "#     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "#     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "#     y_train = y_train.reshape(y_train.shape[0], 1, 2)\n",
        "#     y_test = y_test.reshape(y_test.shape[0], 1, 2)\n",
        "#     input_shape = (1, img_rows, img_cols)\n",
        "# else:\n",
        "#     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "#     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "#     y_train = y_train.reshape(y_train.shape[0], 2, 1)\n",
        "#     y_test = y_test.reshape(y_test.shape[0], 2, 1)\n",
        "#     input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "###x_train = x_train.astype('int')\n",
        "x_test = x_test.astype('int')\n",
        "###x_train = np.clip(x_train, 0, 1)\n",
        "x_test = np.clip(x_test, 0, 1)\n",
        "#x_train /= 255\n",
        "#x_test /= 255\n",
        "#print('x_train shape:', x_train.shape)\n",
        "#print(x_train.shape[0], 'train samples')\n",
        "#print(x_test.shape[0], 'test samples')\n",
        "#print('y_train shape:', y_train.shape)\n",
        "#print(y_train.shape[0], 'train samples')\n",
        "#print(y_test.shape[0], 'test samples')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjpJZTcYsCYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#plot sample events\n",
        "\n",
        "#for n in range(min(16,len(x_train))):\n",
        "#  plt.subplot(4, 4, n+1)\n",
        "#  plt.imshow(x_train[n,0])\n",
        "\n",
        "\n",
        "for n in range(1):\n",
        "  for k in range(int(100*(prob_noise+0.10))):\n",
        "    rnumber = np.random.randint(0,len(x_test))\n",
        "    x,y,z = x_test[rnumber,0].nonzero()\n",
        "    from mpl_toolkits.mplot3d import Axes3D\n",
        "    fig = plt.figure()\n",
        "    ax = fig.add_subplot(111, projection='3d')\n",
        "    ax.scatter(x, y, z, zdir='z', c= 'red', s=5, alpha=0.9)\n",
        "    \n",
        "    \n",
        "    ax.set_xlabel('X')\n",
        "    ax.set_ylabel('Y')\n",
        "    ax.set_zlabel('Z (depth)')\n",
        "  \n",
        "    \n",
        "    for j in range(len(y_test[rnumber])):\n",
        "    # Data for a three-dimensional line\n",
        "       #print(\"index \",k,j)\n",
        "       #print(\"ytrain \", y_train[rnumber])\n",
        "       zline = np.linspace(0, 28, 100)\n",
        "       xline = y_test[rnumber,j,0]*det_width+y_test[rnumber,j,1]*slope_mult*zline \n",
        "       yline = y_test[rnumber,j,2]*det_width+y_test[rnumber,j,3]*slope_mult*zline \n",
        "###       xline = 100*y_test[rnumber,k,0]+100/slope_scale*y_test[rnumber,k,1]*zline\n",
        "###       yline = 100*y_test[rnumber,k,2]+100/slope_scale*y_test[rnumber,k,3]*zline\n",
        "       ax.plot3D(xline, yline, zline,  'green', alpha=0.5)\n",
        "    \n",
        "    ax.view_init(elev=35., azim=45)\n",
        "    ax.scatter([0,det_width],[0,det_width],[0,det_depth], c= 'blue', s=0)\n",
        "\n",
        "    # set axes range\n",
        "    ax.set_xlim3d(0,det_width)\n",
        "    ax.set_xlim3d(0,det_width)\n",
        "    ax.set_xlim3d(0,det_depth)\n",
        "    #ax.axis('equal')\n",
        "    \n",
        "    print('event_'+str(efficiency)+\"_\"+str(prob_noise)+\"_\"+str(k)+'.png')\n",
        "    plt.savefig('event_'+str(efficiency)+\"_\"+str(prob_noise)+\"_\"+str(k)+'.png')\n",
        "    plt.show()\n",
        "  \n",
        "#  plt.imshow(x_train[np.random.randint(0,len(x_train)),0])\n",
        "#  plt.show()\n",
        "#   plt.savefig('event.png')\n",
        "#plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#for i in range(img_rows):\n",
        "#    print (\" \")\n",
        "#    for j in range (img_cols):\n",
        "#        print (x_train[0,0,i,j], end=' ')\n",
        "#print (\" \")\n",
        "#print (\"y_train[0] = \",y_train[0])\n",
        "#print (\"y_test[0] = \",y_test[0])\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "#y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "#y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "#print (\"Class = \",y_train[0])\n",
        "\n",
        "\n",
        "\n",
        "#sys.exit(\"Stopping here\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz-ZxGnuALZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#printing TPU information\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "  print('ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!')\n",
        "else:\n",
        "  tpu_address = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  print ('TPU address is', tpu_address)\n",
        "\n",
        "  with tf.Session(tpu_address) as session:\n",
        "    devices = session.list_devices()\n",
        "    \n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(devices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "69VjCyS0xBLa"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TG4dJAfDXpZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "start_training_time = time.time()\n",
        "\n",
        "if 'COLAB_TPU_ADDR' not in os.environ:\n",
        "\n",
        "  model = Sequential()\n",
        "  input_shape=(1,det_width, det_width, det_depth)\n",
        "\n",
        "  print(\"input_shape \",input_shape)\n",
        "\n",
        "  model.add(Reshape((det_width, det_width, det_depth,1),\n",
        "                                  input_shape=input_shape))\n",
        "  model.add(Conv3D(32, (3, 3, 3), activation='relu'))  #8\n",
        "  model.add(Conv3D(32, (3, 3, 3), activation='relu'))  #8\n",
        "#  model.add(Conv3D(32, (3, 3, 3), activation='relu'))  #added\n",
        "  model.add(MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "  model.add(Conv3D(128, (3, 3, 3), activation='relu'))  #32\n",
        "  model.add(Conv3D(128, (3, 3, 3), activation='relu'))  #32\n",
        "#  model.add(Conv3D(128, (3, 3, 3), activation='relu'))  #added\n",
        "  model.add(Dropout(0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(400, activation='relu'))  # 400\n",
        "#  model.add(Dense(400))  # added\n",
        "  #model.add(Dropout(0.5))\n",
        "  #model.add(Dense(2, activation='tanh'))\n",
        "\n",
        "\n",
        "  model.add(RepeatVector(max_tracks))\n",
        "  model.add(LSTM(400, return_sequences=True))\n",
        "  model.add(TimeDistributed(Dense(4)))\n",
        "\n",
        "  # model.add(Flatten(input_shape=input_shape))\n",
        "  # #model.add(Reshape(input_shape - (1, ), input_shape=input_shape))\n",
        "  # model.add(Dense(32, activation='relu'))\n",
        "  # model.add(Dense(32, activation='relu'))\n",
        "  # model.add(Dense(32, activation='relu'))\n",
        "  # model.add(Dense(32, activation='relu'))\n",
        "  # #model.add(Dense(32, activation='relu'))\n",
        "  # #model.add(Dense(32, activation='relu'))\n",
        "  # model.add(Dropout(0.5))\n",
        "  # model.add(Dense(2, activation='tanh'))\n",
        "\n",
        "\n",
        "  #model.add(Reshape((1, 2),input_shape=(2,)))\n",
        "  model.add(Reshape((max_tracks, 4),input_shape=(4*max_tracks,)))\n",
        "\n",
        "else:\n",
        "\n",
        "  model = tf.keras.layers.Sequential()\n",
        "  input_shape=(1,det_width, det_width, det_depth)\n",
        "\n",
        "  print(\"input_shape \",input_shape)\n",
        "\n",
        "  model.add(Reshape((det_width, det_width, det_depth,1),\n",
        "                                  input_shape=input_shape))\n",
        "  model.add(Conv3D(32, (3, 3, 3), activation='relu'))  #8\n",
        "  model.add(tf.keras.layers.Conv3D(32, (3, 3, 3), activation='relu'))  #8\n",
        "  model.add(tf.keras.layers.Conv3D(32, (3, 3, 3), activation='relu'))  #added\n",
        "  model.add(tf.keras.layers.MaxPooling3D(pool_size=(2, 2, 2)))\n",
        "  model.add(tf.keras.layers.Conv3D(128, (3, 3, 3), activation='relu'))  #32\n",
        "  model.add(tf.keras.layers.Conv3D(128, (3, 3, 3), activation='relu'))  #32\n",
        "  model.add(tf.keras.layers.Conv3D(128, (3, 3, 3), activation='relu'))  #added\n",
        "  model.add(tf.keras.layers.Dropout(0.25))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(400, activation='relu'))  # 400\n",
        "  model.add(tf.keras.layers.Dense(400))  # added\n",
        "  #model.add(Dropout(0.5))\n",
        "  #model.add(Dense(2, activation='tanh'))\n",
        "\n",
        "\n",
        "  model.add(tf.keras.layers.RepeatVector(max_tracks))\n",
        "  model.add(tf.keras.layers.LSTM(400, return_sequences=True))\n",
        "  model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(4)))\n",
        "\n",
        "  # model.add(Flatten(input_shape=input_shape))\n",
        "  # #model.add(Reshape(input_shape - (1, ), input_shape=input_shape))\n",
        "  # model.add(Dense(32, activation='relu'))\n",
        "  # model.add(Dense(32, activation='relu'))\n",
        "  # model.add(Dense(32, activation='relu'))\n",
        "  # model.add(Dense(32, activation='relu'))\n",
        "  # #model.add(Dense(32, activation='relu'))\n",
        "  # #model.add(Dense(32, activation='relu'))\n",
        "  # model.add(Dropout(0.5))\n",
        "  # model.add(Dense(2, activation='tanh'))\n",
        "\n",
        "\n",
        "  #model.add(Reshape((1, 2),input_shape=(2,)))\n",
        "  model.add(tf.keras.layers.Reshape((max_tracks, 4),input_shape=(4*max_tracks,)))  \n",
        "  \n",
        "\n",
        "# print outputs for each layer\n",
        "outputs =  [layer.output for layer in model.layers]\n",
        "print (outputs)\n",
        "print (model.summary())\n",
        "\n",
        "print (\"plotting model\")\n",
        "plot_model(model, to_file='model.png',rankdir='LR',show_shapes=False,show_layer_names=False )  ###, show_shapes=True\n",
        "\n",
        "print (\"Showing model\")\n",
        "from IPython.display import Image\n",
        "display(Image(filename='model.png'))\n",
        "!ls\n",
        "print (\"Model shown\")\n",
        "\n",
        "#sys.exit(\"Stopping here\")\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "    Converts a Keras model to dot format and save to a file.\n",
        "    # Arguments\n",
        "        model: A Keras model instance\n",
        "        to_file: File name of the plot image.\n",
        "        show_shapes: whether to display shape information.\n",
        "        show_layer_names: whether to display layer names.\n",
        "        rankdir: `rankdir` argument passed to PyDot,\n",
        "            a string specifying the format of the plot:\n",
        "            'TB' creates a vertical plot;\n",
        "            'LR' creates a horizontal plot.\n",
        "        expand_nested: whether to expand nested models into clusters.\n",
        "        dpi: dot DPI.\n",
        "'''\n",
        "\n",
        "# Vizualizing model structure\n",
        "\n",
        "sequential_model_to_ascii_printout(model)\n",
        "\n",
        "\n",
        "#history=model.fit(x_train, y_train,\n",
        "#          batch_size=batch_size_NN,\n",
        "#          epochs=epochs,\n",
        "#          verbose=1,\n",
        "#          validation_data=(x_test, y_test))\n",
        "\n",
        "\n",
        "def data_generator(batch_size_gen=batch_size_NN,prob_noise=prob_noise,n_tracks=mean_tracks):\n",
        "  \n",
        " while True: \n",
        "   # the data, split between train and test sets\n",
        "   #(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "   x_train, y_train = gen_n_tracks(batch_size=batch_size_gen,n_tracks=mean_tracks).next()\n",
        "\n",
        "   #y_train = y_train/100\n",
        "\n",
        "   # add noise\n",
        "   noise_train = gen_noise(batch_size=batch_size_gen,prob_noise=prob_noise).next()\n",
        "   x_train = x_train+noise_train\n",
        "   \n",
        "   #print(\"x_train: \",x_train.shape)\n",
        "   #print(\"y_train: \",y_train.shape)\n",
        "   yield x_train, y_train\n",
        "   \n",
        "#print(\"generator \",data_generator())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfPkKytjE0DN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#using TPU model!!!\n",
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "if 'COLAB_TPU_ADDR'  in os.environ:  \n",
        "  TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "  model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "     model,\n",
        "     strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))\n",
        "\n",
        "  model.compile(optimizer=tf.train.AdamOptimizer(), loss='mse')\n",
        "else:\n",
        "#  model.compile(\n",
        "#      optimizer=Adam(lr=0.001, beta_1=0.9, beta_2=0.999, \n",
        "#                                      epsilon=1e-8), loss='mse')\n",
        "#  rms = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.1)\n",
        "#  model.compile(optimizer=rms, loss='mse')\n",
        "#  model.compile(optimizer='Adam', loss='mean_squared_error')\n",
        "  model.compile(optimizer='sgd', loss='mean_squared_error')\n",
        "\n",
        "#model.compile(optimizer=tf.train.AdamOptimizer(), loss='mse')\n",
        "#model.compile(loss='mean_squared_error', optimizer='Adam')\n",
        "\n",
        "#model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#              optimizer=keras.optimizers.Adadelta(),\n",
        "#              metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3PucksX_9Kt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#del model\n",
        "#model = load_model('partly_trained.h5')\n",
        "\n",
        "# patient early stopping\n",
        "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=12)  # 'val_loss'\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='loss', mode='min', verbose=1,\n",
        "                     save_best_only=True)  # 'val_loss'\n",
        "\n",
        "#train with fit_generator - generate events on flight\n",
        "# pre-training with rms optimizer \n",
        "history=model.fit_generator(data_generator(prob_noise=prob_noise, n_tracks=mean_tracks),\n",
        "                            steps_per_epoch=steps_per_epoch,\n",
        "                            #validation_data=data_generator(), \n",
        "                            #validation_steps=steps_per_epoch,\n",
        "                            epochs = pre_epochs, callbacks=[es, mc])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZNN42Wjd07s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "###plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.xlim(3, None)\n",
        "plt.ylim(ymax = 1.2*history.history['loss'][min(len(history.history['loss']),3)-1], ymin = 0)\n",
        "print(\"history\",history.history['loss'])\n",
        "\n",
        "auxName = 'pretraining_'+str(efficiency)+'_'+str(prob_noise)+'.png'\n",
        "plt.savefig(auxName)\n",
        "  \n",
        "plt.show()\n",
        "#plt.savefig('training.png')\n",
        "plt.clf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUApaF21WHYI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "def train_model(model, prob_noise=prob_noise):\n",
        "\n",
        "  print(\"Training with ADAM optimizer, efficiency, prob_noise = \",efficiency,prob_noise)\n",
        "  \n",
        "  #recompile the model with Adam optimizer \n",
        "  model.compile(optimizer='Adam', loss='mean_squared_error')\n",
        "\n",
        "  # patient early stopping\n",
        "  es_noise = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=12)  # 'val_loss'\n",
        "  mc_noise = ModelCheckpoint('best_model.h5', monitor='loss', mode='min', verbose=1,\n",
        "                     save_best_only=True)  # 'val_loss'\n",
        "\n",
        "\n",
        "  #train with fit_generator - generate events on flight\n",
        "  history=model.fit_generator(data_generator(prob_noise=prob_noise, n_tracks=mean_tracks),\n",
        "                            steps_per_epoch=steps_per_epoch,\n",
        "                            #validation_data=data_generator(), \n",
        "                            #validation_steps=steps_per_epoch,\n",
        "                            epochs = epochs, callbacks=[es_noise, mc_noise])\n",
        "\n",
        "\n",
        "  # load the saved model\n",
        "  model = load_model('best_model.h5')\n",
        "\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  ###plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.xlim(3, None)\n",
        "  plt.ylim(ymax = 1.2*history.history['loss'][min(len(history.history['loss']),3)-1], ymin = 0)\n",
        "  print(\"history\",history.history['loss'])\n",
        "\n",
        "  auxName = 'training_'+str(efficiency)+'_'+str(prob_noise)+'.png'\n",
        "  plt.savefig(auxName)\n",
        "  \n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "  \n",
        "  \n",
        "    #recompile the model with SGD optimizer \n",
        "  model.compile(optimizer='SGD', loss='mean_squared_error')\n",
        "\n",
        "  \n",
        "\n",
        "  #train with fit_generator - generate events on flight\n",
        "  history=model.fit_generator(data_generator(prob_noise=prob_noise, n_tracks=mean_tracks),\n",
        "                            steps_per_epoch=steps_per_epoch,\n",
        "                            #validation_data=data_generator(), \n",
        "                            #validation_steps=steps_per_epoch,\n",
        "                            epochs = post_epochs, callbacks=[es_noise, mc_noise])\n",
        "\n",
        "\n",
        "\n",
        "  # load the saved model\n",
        "  model = load_model('best_model.h5')\n",
        "  \n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  ###plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.xlim(3, None)\n",
        "  plt.ylim(ymax = 1.2*history.history['loss'][min(len(history.history['loss']),3)-1], ymin = 0)\n",
        "  print(\"history\",history.history['loss'])\n",
        "\n",
        "  auxName = 'trainingSGD_'+str(efficiency)+'_'+str(prob_noise)+'.png'\n",
        "  plt.savefig(auxName)\n",
        "  \n",
        "  plt.show()\n",
        "  plt.clf()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asMusjfT3RGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_testdata(prob_noise = prob_noise):\n",
        "\n",
        "  print(\"Generate test data, efficiency, prob_noise = \",efficiency,prob_noise)\n",
        "\n",
        "  ###x_train, y_train = gen_n_tracks(batch_size=batch_size).next()\n",
        "  x_test, y_test = gen_n_tracks(batch_size=batch_size, n_tracks=mean_tracks).next()\n",
        "\n",
        "  # add noise\n",
        "  noise_test = gen_noise(batch_size=batch_size, prob_noise=prob_noise).next()\n",
        "  x_test  = x_test+noise_test\n",
        " \n",
        "\n",
        "  x_test = x_test.astype('int')\n",
        "  #clip to 1\n",
        "  x_test = np.clip(x_test, 0, 1)\n",
        "\n",
        "  return x_test, y_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3crO8AqTtz6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_sample():\n",
        "\n",
        "  #plot sample events\n",
        "  print(\"plotting sample events, efficiency, prob_noise = \",efficiency,prob_noise)\n",
        "\n",
        "  for n in range(1):\n",
        "    for k in range(int(100*(prob_noise+0.10))):\n",
        "      rnumber = np.random.randint(0,len(x_test))\n",
        "      x,y,z = x_test[rnumber,0].nonzero()\n",
        "      from mpl_toolkits.mplot3d import Axes3D\n",
        "      fig = plt.figure()\n",
        "      ax = fig.add_subplot(111, projection='3d')\n",
        "      ax.scatter(x, y, z, zdir='z', c= 'red', s=5, alpha=0.9)\n",
        "    \n",
        "    \n",
        "      ax.set_xlabel('X')\n",
        "      ax.set_ylabel('Y')\n",
        "      ax.set_zlabel('Z (depth)')\n",
        "  \n",
        "    \n",
        "      for j in range(len(y_test[rnumber])):\n",
        "      # Data for a three-dimensional line\n",
        "         #print(\"index \",k)\n",
        "         #print(\"ytrain \", y_train[rnumber])\n",
        "         zline = np.linspace(0, 28, 100)\n",
        "         xline = y_test[rnumber,j,0]*det_width+y_test[rnumber,j,1]*slope_mult*zline \n",
        "         yline = y_test[rnumber,j,2]*det_width+y_test[rnumber,j,3]*slope_mult*zline \n",
        "###       xline = 100*y_test[rnumber,k,0]+100/slope_scale*y_test[rnumber,k,1]*zline\n",
        "###       yline = 100*y_test[rnumber,k,2]+100/slope_scale*y_test[rnumber,k,3]*zline\n",
        "         ax.plot3D(xline, yline, zline,  'green', alpha=0.5)\n",
        "    \n",
        "      ax.view_init(elev=35., azim=45)\n",
        "      ax.scatter([0,det_width],[0,det_width],[0,det_depth], c= 'blue', s=0)\n",
        "\n",
        "      # set axes range\n",
        "      ax.set_xlim3d(0,det_width)\n",
        "      ax.set_xlim3d(0,det_width)\n",
        "      ax.set_xlim3d(0,det_depth)\n",
        "      #ax.axis('equal')\n",
        "\n",
        "      print('event_'+str(efficiency)+\"_\"+str(prob_noise)+\"_\"+str(k)+'.png')\n",
        "      plt.savefig('event_'+str(efficiency)+\"_\"+str(prob_noise)+\"_\"+str(k)+'.png')\n",
        "      plt.show()\n",
        "  \n",
        "#  plt.imshow(x_train[np.random.randint(0,len(x_train)),0])\n",
        "#  plt.show()\n",
        "#plt.savefig('event.png')\n",
        "#plt.clf()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#sys.exit(\"Stopping here\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdnovmzVXksz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model):\n",
        "\n",
        "  print(\"Predict with trained NN, efficiency, prob_noise = \",efficiency,prob_noise)\n",
        "\n",
        "  start_pattern_time = time.time()\n",
        "\n",
        "  if 'COLAB_TPU_ADDR'  in os.environ:\n",
        "  # converting tpu_model to the cpu_model\n",
        "   model = model.sync_to_cpu()\n",
        "\n",
        "\n",
        "# make a prediction\n",
        "#batch_size=2\n",
        "  print(\"x_test.shape\", x_test.shape)\n",
        "\n",
        "  y_new = model.predict(x_test)\n",
        "\n",
        "  print (model.summary())\n",
        "  print(\"y_new.shape\", y_new.shape)\n",
        "\n",
        "  end_pattern_time = time.time()\n",
        "\n",
        "  return y_new"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imwO0UcrmClb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "'''\n",
        "# fit tracks using ROOT fit\n",
        "y0_fit = []\n",
        "for i in range(len(x_test)):\n",
        "    y0_row = []\n",
        "\n",
        "    grxzv = []\n",
        "    xzfitv = []\n",
        "    xztruev = []\n",
        "    xzdnnv = []\n",
        "    \n",
        "\n",
        "    for j in range(len(y_new[i])):\n",
        "        if i<30:\n",
        "            print (\"true  x0, Ax  \", (y_test[i])[j])\n",
        "            print (\"pred  x0, Ax  \", (y_new[i])[j])\n",
        "\n",
        "\n",
        "\n",
        "            for m in range(img_rows):\n",
        "              print (\" \")\n",
        "              for n in range (img_cols):\n",
        "                 if abs(n - ( (((y_new[i])[j])[1]*100/slope_scale*m) + ((y_new[i])[j])[0]*100 ) ) < 4:\n",
        "                   print (x_test[i,0,m,n]+5, end=' ')\n",
        "                 else:\n",
        "                   print (x_test[i,0,m,n], end=' ')\n",
        "            print(\" \")\n",
        "            #print(\" value at x=14 : \",(((y_new[i])[j])[1]*100/slope_scale*14) + ((y_new[i])[j])[0]*100 )\n",
        "\n",
        "        N = 0\n",
        "        x = []\n",
        "        y = []\n",
        "        x_err = []\n",
        "        y_err = []\n",
        "\n",
        "        for m in range(img_rows):\n",
        "            for n in range (img_cols):\n",
        "                if abs(n - ( (((y_new[i])[j])[1]*100/slope_scale*m) + ((y_new[i])[j])[0]*100 ) ) < 4:\n",
        "                  #if i<10:\n",
        "                  #   print (\" i,m,n x_test \",i,m,n,x_test[i,0,m,n])\n",
        "                  if x_test[i,0,m,n] == 1:\n",
        "                      N = N+1\n",
        "                      x.append(m)\n",
        "                      y.append(n)\n",
        "                      x_err.append(0.3)\n",
        "                      y_err.append(0.3)\n",
        "        if i<10:\n",
        "          print (\"N \", N) \n",
        "          print (\"x vector \", x) \n",
        "          print (\"y vector \", y) \n",
        "\n",
        "        if N>13:\n",
        "           xzfit = TF1(\"xzfit\",\"pol1\",0,27)\n",
        "           ###xzfit2 = TF1(\"xzfit2\",\"pol1\",0,27)\n",
        "           grxz  = TGraphErrors(N,np.array(x,'d'),np.array(y,'d'), np.array(x_err,'d'), np.array(y_err,'d') )\n",
        "           grxz.SetMarkerColor(ROOT.kRed)\n",
        "           grxz.SetLineColor(ROOT.kRed)\n",
        "           #grxz.Print()\n",
        "\n",
        "           err = grxz.Fit(xzfit,\" +rob=0.70,q \")\n",
        "           ##err = grxz.Fit(xzfit2,\"  \")\n",
        "           #print (\"status \",err)\n",
        "           x0 = xzfit.GetParameter(0)/100.\n",
        "           Ax = xzfit.GetParameter(1)*slope_scale/100.\n",
        "           chi2 = xzfit.GetChisquare()\n",
        "           NDF = xzfit.GetNDF()\n",
        "           prob = xzfit.GetProb()\n",
        "\n",
        "           grxzv.append(grxz)\n",
        "           xzfitv.append(xzfit)\n",
        "           \n",
        "           y0_row.append([x0,Ax,chi2,NDF,prob,N,xzfit.GetNumberFitPoints()])\n",
        "           if i<30:\n",
        "             print (\"fit x0, Ax  \", x0, Ax)\n",
        "           #del xzfit\n",
        "           #del grxz\n",
        "           #print (\"Points: \",N, xzfit.GetNumberFitPoints())\n",
        "\n",
        "\n",
        "              ###grxz.Draw(\"aps\")\n",
        "              #print(\"MWMW \",(y_test[i])[0])\n",
        "              #print(\"MWMW \",((y_test[i])[0])[0])\n",
        "           if len(y_new[i])>0:\n",
        "                xztrue = TF1(\"xztrue\",\"pol1\",0,27)\n",
        "                #print (\"true track: \",((y_test[i])[0])[0], ((y_test[i])[0])[1] )\n",
        "                xztrue.SetParameter(0, float(((y_test[i])[j])[0]*100.) )\n",
        "                xztrue.SetParameter(1, float(((y_test[i])[j])[1]*100./slope_scale) )\n",
        "                xztrue.SetLineColor(ROOT.kGreen)\n",
        "\n",
        "                xzdnn = TF1(\"xzdnn\",\"pol1\",0,27)\n",
        "                #print (\"dnn track: \",((y_new[i])[0])[0], ((y_new[i])[0])[1] )\n",
        "                xzdnn.SetParameter(0, float(((y_new[i])[j])[0]*100.) )\n",
        "                xzdnn.SetParameter(1, float(((y_new[i])[j])[1]*100./slope_scale) )\n",
        "                xzdnn.SetLineColor(ROOT.kBlue)\n",
        "\n",
        "\n",
        "                xzdnnv.append(xzdnn)\n",
        "                xztruev.append(xztrue)\n",
        "                ##xzdnn.Draw(\"same\")\n",
        "                ##xztrue.Draw(\"same\")\n",
        "\n",
        "\n",
        "\n",
        "           \n",
        "        else:\n",
        "           y0_row.append([-999,-999,-999,-999,-999,-999,-999])\n",
        "\n",
        "    if i<150:   \n",
        "       MyCanv =  TCanvas( \"MyCanv\", \"MyCanv\", 800, 600 )\n",
        "       legend = ROOT.TLegend(0.75, 0.75, 0.95, 0.95)\n",
        "       Na = 0\n",
        "       xa = []\n",
        "       ya = []\n",
        "       xa_err = []\n",
        "       ya_err = []\n",
        "\n",
        "       for m in range(img_rows):\n",
        "            for n in range (img_cols):\n",
        "                  if x_test[i,0,m,n] == 1:\n",
        "                      Na = Na+1\n",
        "                      xa.append(m)\n",
        "                      ya.append(n)\n",
        "                      xa_err.append(0.3)\n",
        "                      ya_err.append(0.3)\n",
        "       grxza  = TGraphErrors(Na,np.array(xa,'d'),np.array(ya,'d'), np.array(xa_err,'d'), np.array(ya_err,'d') )\n",
        "       grxza.Draw(\"ap\")\n",
        "       grxza.GetXaxis().SetRangeUser(-0.5,27.5)\n",
        "       grxza.GetYaxis().SetRangeUser(-0.5,27.5)\n",
        "       grxza.Draw(\"ap\")\n",
        "       MyCanv.Update()\n",
        "\n",
        "       legend.AddEntry(grxza, \"hits\", \"lp\")\n",
        "       if len(grxzv)>0:\n",
        "        legend.AddEntry(grxzv[0], \"assoc. hits\", \"lp\")\n",
        "        legend.AddEntry(xzfitv[0], \"fitted track\", \"lp\")\n",
        "        legend.AddEntry(xzdnnv[0], \"dnn track\", \"lp\")\n",
        "        legend.AddEntry(xztruev[0], \"true track\", \"lp\")\n",
        "        legend.Draw()\n",
        "\n",
        "       for k in range(len(grxzv)):  \n",
        "            grxzv[k].Draw(\"p same\")\n",
        "            xzfitv[k].Draw(\"same\") \n",
        "            xzdnnv[k].Draw(\"same\") \n",
        "            xztruev[k].Draw(\"same\") \n",
        "\n",
        "       ttt = \"images/fit_\"+str(i)+\".png\"\n",
        "       print (\"saving \",i, ttt)\n",
        "       MyCanv.SaveAs(ttt)\n",
        "       MyCanv.Close()\n",
        "\n",
        "    y0_fit.append(y0_row)\n",
        "\n",
        "end_fit_time = time.time()\n",
        "'''\n",
        "\n",
        "\n",
        "'''\n",
        "# Fill ntuple\n",
        "ofn = 'aptuple.root'\n",
        "\n",
        "outfile = TFile( ofn, 'RECREATE', 'ROOT file with an NTuple' )\n",
        "outfile.cd()\n",
        "\n",
        "#ntuple  = TNtuple( 'ntuple', 'pattern recognition') #'x0_true:Ax_true:x0_reco1:Ax_reco1:x0_dnn1:Ax_dnn1:x0_reco2:Ax_reco2:x0_dnn2:Ax_dnn2:x0_reco3:Ax_reco3:x0_dnn3:Ax_dnn3' )\n",
        "\n",
        "#for i in range(len(y0_fit)):\n",
        "    #words = string.split( line )\n",
        "    #row = map( float, words )\n",
        "#    if len(y_test[i])+len(y0_fit[i])+len(y_new[i])<\n",
        "#       apply( ntuple.Fill, np.array(np.append(y_test[i],[y0_fit[i],y_new[i]])))\n",
        "#ntuple.Write()\n",
        "\n",
        "\n",
        "x0_true1 = np.array([0.],'f')\n",
        "x0_true2 = np.array([0.],'f')\n",
        "x0_true3 = np.array([0.],'f')\n",
        "Ax_true1 = np.array([0.],'f')\n",
        "Ax_true2 = np.array([0.],'f')\n",
        "Ax_true3 = np.array([0.],'f')\n",
        "\n",
        "x0_fit1 = np.array([0.],'f')\n",
        "x0_fit2 = np.array([0.],'f')\n",
        "x0_fit3 = np.array([0.],'f')\n",
        "Ax_fit1 = np.array([0.],'f')\n",
        "Ax_fit2 = np.array([0.],'f')\n",
        "Ax_fit3 = np.array([0.],'f')\n",
        "\n",
        "chi2_fit1 = np.array([0.],'f')\n",
        "chi2_fit2 = np.array([0.],'f')\n",
        "chi2_fit3 = np.array([0.],'f')\n",
        "NDF_fit1 = np.array([0.],'f')\n",
        "NDF_fit2 = np.array([0.],'f')\n",
        "NDF_fit3 = np.array([0.],'f')\n",
        "prob_fit1 = np.array([0.],'f')\n",
        "prob_fit2 = np.array([0.],'f')\n",
        "prob_fit3 = np.array([0.],'f')\n",
        "N_fit1 = np.array([0.],'f')\n",
        "N_fit2 = np.array([0.],'f')\n",
        "N_fit3 = np.array([0.],'f')\n",
        "Nfit_fit1 = np.array([0.],'f')\n",
        "Nfit_fit2 = np.array([0.],'f')\n",
        "Nfit_fit3 = np.array([0.],'f')\n",
        "\n",
        "\n",
        "x0_dnn1 = np.array([0.],'f')\n",
        "x0_dnn2 = np.array([0.],'f')\n",
        "x0_dnn3 = np.array([0.],'f')\n",
        "Ax_dnn1 = np.array([0.],'f')\n",
        "Ax_dnn2 = np.array([0.],'f')\n",
        "Ax_dnn3 = np.array([0.],'f')\n",
        "\n",
        "tree = TTree( 'ntuple', 'pattern recognition' )\n",
        "\n",
        "tree.Branch( 'x0_true1', x0_true1, 'x0_true1/F' )\n",
        "tree.Branch( 'x0_true2', x0_true2, 'x0_true2/F' )\n",
        "tree.Branch( 'x0_true3', x0_true3, 'x0_true3/F' )\n",
        "tree.Branch( 'Ax_true1', Ax_true1, 'A0_true1/F' )\n",
        "tree.Branch( 'Ax_true2', Ax_true2, 'A0_true2/F' )\n",
        "tree.Branch( 'Ax_true3', Ax_true3, 'A0_true3/F' ) \n",
        "\n",
        "tree.Branch( 'x0_fit1', x0_fit1, 'x0_fit1/F' )\n",
        "tree.Branch( 'x0_fit2', x0_fit2, 'x0_fit2/F' )\n",
        "tree.Branch( 'x0_fit3', x0_fit3, 'x0_fit3/F' )\n",
        "tree.Branch( 'Ax_fit1', Ax_fit1, 'A0_fit1/F' )\n",
        "tree.Branch( 'Ax_fit2', Ax_fit2, 'A0_fit2/F' )\n",
        "tree.Branch( 'Ax_fit3', Ax_fit3, 'A0_fit3/F' ) \n",
        "\n",
        "tree.Branch( 'chi2_fit1', chi2_fit1, 'chi2_fit1/F' )\n",
        "tree.Branch( 'chi2_fit2', chi2_fit2, 'chi2_fit2/F' )\n",
        "tree.Branch( 'chi2_fit3', chi2_fit3, 'chi2_fit3/F' )\n",
        "tree.Branch( 'NDF_fit1', NDF_fit1, 'NDF_fit1/F' )\n",
        "tree.Branch( 'NDF_fit2', NDF_fit2, 'NDF_fit2/F' )\n",
        "tree.Branch( 'NDF_fit3', NDF_fit3, 'NDF_fit3/F' ) \n",
        "tree.Branch( 'prob_fit1', prob_fit1, 'prob_fit1/F' )\n",
        "tree.Branch( 'prob_fit2', prob_fit2, 'prob_fit2/F' )\n",
        "tree.Branch( 'prob_fit3', prob_fit3, 'prob_fit3/F' ) \n",
        "tree.Branch( 'N_fit1', N_fit1, 'N_fit1/F' )\n",
        "tree.Branch( 'N_fit2', N_fit2, 'N_fit2/F' )\n",
        "tree.Branch( 'N_fit3', N_fit3, 'N_fit3/F' ) \n",
        "tree.Branch( 'Nfit_fit1', Nfit_fit1, 'Nfit_fit1/F' )\n",
        "tree.Branch( 'Nfit_fit2', Nfit_fit2, 'Nfit_fit2/F' )\n",
        "tree.Branch( 'Nfit_fit3', Nfit_fit3, 'Nfit_fit3/F' ) \n",
        "\n",
        "\n",
        "tree.Branch( 'x0_dnn1', x0_dnn1, 'x0_dnn1/F' )\n",
        "tree.Branch( 'x0_dnn2', x0_dnn2, 'x0_dnn2/F' )\n",
        "tree.Branch( 'x0_dnn3', x0_dnn3, 'x0_dnn3/F' )\n",
        "tree.Branch( 'Ax_dnn1', Ax_dnn1, 'A0_dnn1/F' )\n",
        "tree.Branch( 'Ax_dnn2', Ax_dnn2, 'A0_dnn2/F' )\n",
        "tree.Branch( 'Ax_dnn3', Ax_dnn3, 'A0_dnn3/F' ) \n",
        "\n",
        "print (\"len(y_test) \",len(y_test))\n",
        "for i in range(len(y_test)):\n",
        "\n",
        "  if len(y_test[i])>0:\n",
        "   x0_true1[0] = (y_test[i])[0][0]\n",
        "   Ax_true1[0] = (y_test[i])[0][1]\n",
        "\n",
        "   x0_fit1[0] = (y0_fit[i])[0][0]\n",
        "   Ax_fit1[0] = (y0_fit[i])[0][1]\n",
        "\n",
        "   chi2_fit1[0] = (y0_fit[i])[0][2]\n",
        "   NDF_fit1[0]  = (y0_fit[i])[0][3]\n",
        "   prob_fit1[0] = (y0_fit[i])[0][4]\n",
        "   N_fit1[0]    = (y0_fit[i])[0][5]\n",
        "   Nfit_fit1[0] = (y0_fit[i])[0][6]\n",
        "\n",
        "   x0_dnn1[0] = (y_new[i])[0][0]\n",
        "   Ax_dnn1[0] = (y_new[i])[0][1]\n",
        "\n",
        "  if len(y_test[i])>1:\n",
        "   x0_true2[0] = (y_test[i])[1][0]\n",
        "   Ax_true2[0] = (y_test[i])[1][1]\n",
        "\n",
        "   x0_fit2[0] = (y0_fit[i])[1][0]\n",
        "   Ax_fit2[0] = (y0_fit[i])[1][1]\n",
        "\n",
        "   chi2_fit2[0] = (y0_fit[i])[1][2]\n",
        "   NDF_fit2[0]  = (y0_fit[i])[1][3]\n",
        "   prob_fit2[0] = (y0_fit[i])[1][4]\n",
        "   N_fit2[0]    = (y0_fit[i])[1][5]\n",
        "   Nfit_fit2[0] = (y0_fit[i])[1][6]\n",
        " \n",
        "   x0_dnn2[0] = (y_new[i])[1][0]\n",
        "   Ax_dnn2[0] = (y_new[i])[1][1]\n",
        "\n",
        "  if len(y_test[i])>2:\n",
        "   x0_true3[0] = (y_test[i])[2][0]\n",
        "   Ax_true3[0] = (y_test[i])[2][1]\n",
        "\n",
        "   x0_fit3[0] = (y0_fit[i])[2][0]\n",
        "   Ax_fit3[0] = (y0_fit[i])[2][1]\n",
        "\n",
        "   chi2_fit3[0] = (y0_fit[i])[2][2]\n",
        "   NDF_fit3[0]  = (y0_fit[i])[2][3]\n",
        "   prob_fit3[0] = (y0_fit[i])[2][4]\n",
        "   N_fit3[0]    = (y0_fit[i])[2][5]\n",
        "   Nfit_fit3[0] = (y0_fit[i])[2][6]\n",
        "\n",
        "   x0_dnn3[0] = (y_new[i])[2][0]\n",
        "   Ax_dnn3[0] = (y_new[i])[2][1]\n",
        "\n",
        "\n",
        " \n",
        "  tree.Fill()\n",
        "  #tree.Print()\n",
        "\n",
        "tree.Write()\n",
        "outfile.Close()\n",
        "\n",
        "\n",
        "#TF1 *xzfit = new TF1(\"xzfit\",\"pol1\",-50,2500);\n",
        "#TGraphErrors *grxz = new TGraphErrors(nx,zhx,xh,zhx_err,xh_err);\n",
        "\n",
        "#grxz->Fit(xzfit,\"+robq\");\n",
        "#          double x0 = xzfit->GetParameter(0);\n",
        "#          double Ax = xzfit->GetParameter(1);\n",
        "#          double chi2x = xzfit->GetChisquare();\n",
        "#          int ndfx = xzfit->GetNDF();\n",
        "#          line linex(x0,Ax,0.0,0.0,0.0,chi2x,0.0,ndfx,0,0,0);\n",
        "\n",
        "'''\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGvlPVpUhAIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_predict(y_new = y_new):\n",
        "\n",
        "  print(\"Plot fitted parameters, efficiency, prob_noise = \",efficiency,prob_noise)\n",
        "\n",
        "  print(\"y_new shape :: \",y_new.shape)\n",
        "  \n",
        "  # plot fitted parameters\n",
        "  y0_true = []\n",
        "  y0_pred = []\n",
        "  for i in range(len(x_test)):\n",
        "    y0_true.append((y_test[i])[0])\n",
        "    y0_pred.append((y_new[i])[0])\n",
        "    if i<6:\n",
        "        print (\"true \",y_test[i])\n",
        "        print (\"pred \",y_new[i])\n",
        "        #print (y0_true[i], y0_pred[i])\n",
        "  plt.plot(y0_true, y0_pred, \".\")\n",
        "  plt.ylabel('predicted')\n",
        "  plt.xlabel('true')\n",
        "  print('params_scatter_'+str(efficiency)+'_'+str(prob_noise)+'.png')\n",
        "  plt.savefig('params_scatter_'+str(efficiency)+'_'+str(prob_noise)+'.png')\n",
        " \n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "  # the histogram of the data\n",
        "  columns_true = zip(*y0_true) #transpose rows to columns\n",
        "  columns_pred = zip(*y0_pred) #transpose rows to columns\n",
        "  #diff = columns_pred-columns_true\n",
        "  diff = tuple(np.subtract(columns_pred,columns_true))\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  n, bins, patches = plt.hist(diff[0], 50, normed=1, facecolor='green', alpha=0.30)\n",
        "  # Fit a normal distribution to the data:\n",
        "  mu, std = norm.fit(diff[0])\n",
        "  # Plot the PDF.\n",
        "  xmin, xmax = plt.xlim()\n",
        "  x = np.linspace(xmin, xmax, 100)\n",
        "  p = norm.pdf(x, mu, std)\n",
        "  plt.title(\"slope X: mu = %.2f,  std = %.2f\" % (mu, std))\n",
        "  plt.plot(x, p, 'k', linewidth=2)\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  n, bins, patches = plt.hist(diff[1], 50, normed=1, facecolor='green', alpha=0.30)\n",
        "  # Fit a normal distribution to the data:\n",
        "  mu, std = norm.fit(diff[1])\n",
        "  # Plot the PDF.\n",
        "  xmin, xmax = plt.xlim()\n",
        "  x = np.linspace(xmin, xmax, 100)\n",
        "  p = norm.pdf(x, mu, std)\n",
        "  plt.title(\"offset X: mu = %.2f,  std = %.2f\" % (mu, std))\n",
        "  plt.plot(x, p, 'k', linewidth=2)\n",
        "\n",
        "  print('params_1_'+str(efficiency)+'_'+str(prob_noise)+'.png')\n",
        "  plt.savefig('params_1_'+str(efficiency)+'_'+str(prob_noise)+'.png')\n",
        "\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "  plt.subplot(1, 2, 1)\n",
        "  n, bins, patches = plt.hist(diff[2], 50, normed=1, facecolor='green', alpha=0.30)\n",
        "  # Fit a normal distribution to the data:\n",
        "  mu, std = norm.fit(diff[2])\n",
        "  # Plot the PDF.\n",
        "  xmin, xmax = plt.xlim()\n",
        "  x = np.linspace(xmin, xmax, 100)\n",
        "  p = norm.pdf(x, mu, std)\n",
        "  plt.title(\"slope Y: mu = %.2f,  std = %.2f\" % (mu, std))\n",
        "  plt.plot(x, p, 'k', linewidth=2)\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  n, bins, patches = plt.hist(diff[3], 50, normed=1, facecolor='green', alpha=0.30)\n",
        "  # Fit a normal distribution to the data:\n",
        "  mu, std = norm.fit(diff[3])\n",
        "  # Plot the PDF.\n",
        "  xmin, xmax = plt.xlim()\n",
        "  x = np.linspace(xmin, xmax, 100)\n",
        "  p = norm.pdf(x, mu, std)\n",
        "  plt.title(\"offset Y: mu = %.2f,  std = %.2f\" % (mu, std))\n",
        "  plt.plot(x, p, 'k', linewidth=2)\n",
        "\n",
        "\n",
        "  print('params_2_'+str(efficiency)+'_'+str(prob_noise)+'.png')\n",
        "  plt.savefig('params_2_'+str(efficiency)+'_'+str(prob_noise)+'.png')\n",
        "\n",
        "\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "  \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSdLKmdjh6Uk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def plot_predict_event(y_new = y_new):\n",
        "\n",
        "  #plot sample events with true and reconstructed tracks\n",
        "  print(\"Plot events with predicted tracks, efficiency, prob_noise = \",efficiency,prob_noise)\n",
        "  \n",
        "  print(\"y_new shape :: \",y_new.shape)\n",
        "  \n",
        "\n",
        "  for n in range(8):\n",
        "    for k in range(int(100*(prob_noise+0.10))):\n",
        "      rnumber = np.random.randint(0,len(x_test))\n",
        "      x,y,z = x_test[rnumber,0].nonzero()\n",
        "      from mpl_toolkits.mplot3d import Axes3D\n",
        "      fig = plt.figure()\n",
        "      ax = fig.add_subplot(111, projection='3d')\n",
        "      ax.scatter(x, y, z, zdir='z', c= 'red', s=5, alpha=0.9)\n",
        "    \n",
        "      ax.set_xlabel('X')\n",
        "      ax.set_ylabel('Y')\n",
        "      ax.set_zlabel('Z (depth)')\n",
        "  \n",
        "  \n",
        "   \n",
        "    \n",
        "      for j in range(len(y_test[rnumber])):\n",
        "      # Data for a three-dimensional line\n",
        "         #print(\"index \",k)\n",
        "         #print(\"ytest \", y_test[rnumber])\n",
        "         zline = np.linspace(0, 28, 100)\n",
        "         xline = y_test[rnumber,j,0]*det_width+y_test[rnumber,j,1]*slope_mult*zline \n",
        "         yline = y_test[rnumber,j,2]*det_width+y_test[rnumber,j,3]*slope_mult*zline \n",
        "###       xline = 100*y_test[rnumber,k,0]+100/slope_scale*y_test[rnumber,k,1]*zline\n",
        "###       yline = 100*y_test[rnumber,k,2]+100/slope_scale*y_test[rnumber,k,3]*zline\n",
        "         ax.plot3D(xline, yline, zline,  'green', alpha=0.5)\n",
        "         xline = y_new[rnumber,j,0]*det_width+y_new[rnumber,j,1]*slope_mult*zline \n",
        "         yline = y_new[rnumber,j,2]*det_width+y_new[rnumber,j,3]*slope_mult*zline  \n",
        "###       xline = 100*y_new[rnumber,k,0]+100/slope_scale*y_new[rnumber,k,1]*zline\n",
        "###       yline = 100*y_new[rnumber,k,2]+100/slope_scale*y_new[rnumber,k,3]*zline\n",
        "         ax.plot3D(xline, yline, zline,  'blue', alpha=0.5)\n",
        "    \n",
        "      #ax.view_init(elev=10., azim=0)\n",
        "      ax.scatter([0,det_width],[0,det_width],[0,det_depth], c= 'blue', s=0)\n",
        "\n",
        "      # set axes range\n",
        "      ax.set_xlim3d(0,det_width)\n",
        "      ax.set_xlim3d(0,det_width)\n",
        "      ax.set_xlim3d(0,det_depth)\n",
        "      #ax.axis('equal')\n",
        "\n",
        "      print('event_res_'+str(efficiency)+\"_\"+str(prob_noise)+\"_\"+str(k)+'.png')\n",
        "      plt.savefig('event_res_'+str(efficiency)+\"_\"+str(prob_noise)+\"_\"+str(k)+'.png')\n",
        "\n",
        "\n",
        "      \n",
        "      plt.show()\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPIeVktJf8up",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def write_predict(y_new = y_new):\n",
        "\n",
        "  print(\"Write output data, efficiency, prob_noise = \",efficiency,prob_noise)\n",
        "\n",
        "  print(\"y_new shape :: \",y_new.shape)\n",
        "  \n",
        "\n",
        "  # write the output - true and reconstructed tracks\t\n",
        "  print(\"Writing dnn_output.txt by printing y_new and y_test: \",y_new.shape)  \n",
        "  f= open(\"dnn_output\"+str(efficiency)+\"_\"+str(prob_noise)+\".txt\",\"w+\")\n",
        "  for i in range(len(y_test)):\n",
        "    k = len(y_test[i])\n",
        "    f.write(\"%s \\n\" % k)\n",
        "    for j in range(len(y_test[i])):\n",
        "      for l in range(len(y_test[i][j])):\n",
        "        f.write(\"%s \" % y_test[i][j][l])\n",
        "      f.write(\"\\n\")\n",
        "    for j in range(len(y_new[i])):\n",
        "      for l in range(len(y_new[i][j])):\n",
        "        f.write(\"%s \" % y_new[i][j][l])      \n",
        "      f.write(\"\\n\")\n",
        "    \n",
        "  f.close()\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liz8jKSPXag8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "print(\"number of tracks \",mean_tracks)\n",
        "\n",
        "\n",
        "\n",
        "for prob_noise in [0, 0.050, 0.100, 0.150, 0.200]:\n",
        "#for prob_noise in [0.001, 0.004]:\n",
        "  \n",
        "  train_model(model, prob_noise)\n",
        "  \n",
        "\n",
        "  x_test, y_test = generate_testdata(prob_noise)\n",
        "  plot_sample()\n",
        "  \n",
        "  y_new = predict(model)\n",
        "  print(\"y_new shape: \",y_new.shape)\n",
        "  plot_predict(y_new)\n",
        "  plot_predict_event(y_new)\n",
        "  \n",
        "  write_predict(y_new)\n",
        "  \n",
        "  !zip  /content/dnn_output_0.zip /content/*.png /content/*.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YOzwDrG4aKcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "end_training_time = time.time()\n",
        "\n",
        "\n",
        "\n",
        "!zip  /content/dnn_output_final.zip /content/*.png /content/*.txt\n",
        "\n",
        "\n",
        "\n",
        "print (\"    \")\n",
        "print (\"###########################################################\")\n",
        "print (\"    \")\n",
        "print (\"CPU usage: \")\n",
        "print (\"Deep NN training:      \", end_training_time-start_training_time)\n",
        "#print (\"Pattern recognition:   \", end_pattern_time-start_pattern_time)\n",
        "#print (\"Track fitting:         \", end_fit_time-start_fit_time)\n",
        "print (\"    \")\n",
        "print (\"###########################################################\")\n",
        "print (\"    \")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}